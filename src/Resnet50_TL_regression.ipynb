{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e335b615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n",
      "mean score tensor(0.7565) std score tensor(0.1239)\n",
      "train val test 45000 3741 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.models as tv_models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "import builtins\n",
    "\n",
    "# Set all print statements to flush=True\n",
    "original_print = builtins.print\n",
    "def print(*args, **kwargs):\n",
    "    kwargs.setdefault('flush', True)\n",
    "    original_print(*args, **kwargs)\n",
    "\n",
    "mem_scores = [{},{},{}]\n",
    "for i,dataset in enumerate(['train','val','test']):\n",
    "    with open(f'./lamem/splits/{dataset}_1.txt') as f:\n",
    "        for line in f:\n",
    "            image_id, mem_score = line.strip().split(' ')\n",
    "            mem_scores[i][image_id] = float(mem_score)\n",
    "\n",
    "train_mem_scores, val_mem_scores, test_mem_scores = mem_scores\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        #use resnet50 as the base model\n",
    "        #self.resnet50 = tv_models.resnet50(pretrained=True) #old Pytorch\n",
    "        self.resnet50 = tv_models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        #modified the last layer for binary classification  \n",
    "        self.resnet50.fc=torch.nn.Linear(2048, 1) #new layer          \n",
    "        #freeze all parameters\n",
    "        for p in self.resnet50.parameters():\n",
    "            p.requires_grad = False \n",
    "        #set the parameters of layer4 to be trainable       \n",
    "        for p in self.resnet50.layer4.parameters():\n",
    "            p.requires_grad = True       \n",
    "        #set the parameters of fc to be trainable       \n",
    "        for p in self.resnet50.fc.parameters():\n",
    "            p.requires_grad = True       \n",
    "        \n",
    "    def get_trainable_parameters(self):\n",
    "        pList=list(self.resnet50.layer4.parameters())+list(self.resnet50.fc.parameters())\n",
    "        #pList=list(self.resnet50.fc.parameters())\n",
    "        return pList\n",
    "    \n",
    "    def forward(self,x):\n",
    "        z = self.resnet50(x)\n",
    "        z = z.view(-1)\n",
    "        return z\n",
    "\n",
    "model = Net()\n",
    "device = 'cuda:0'# if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print('model created')\n",
    "\n",
    "# mse = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "batch_size = 32\n",
    "version = 0\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation of training set target values\n",
    "train_mem_scores_values = list(train_mem_scores.values())\n",
    "mean_score = torch.tensor(train_mem_scores_values).mean()\n",
    "std_score = torch.tensor(train_mem_scores_values).std()\n",
    "print('mean score',mean_score,'std score',std_score)\n",
    "\n",
    "# Normalize target values\n",
    "def normalize_scores(scores):\n",
    "    return (scores - mean_score) / std_score\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define a different loss function (e.g., Huber loss)\n",
    "huber_loss = nn.SmoothL1Loss()\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return preprocess(image)\n",
    "\n",
    "print('train val test',len(list(train_mem_scores.keys())), len(list(val_mem_scores.keys())), len(list(test_mem_scores.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9d008ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 1, Average Training Loss: 0.27183915913147405\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 1, Average Validation Loss: 0.25259453655573827\n",
      "save best epoch 0 0.25259453655573827\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 2, Average Training Loss: 0.1495569250592763\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 2, Average Validation Loss: 0.2720186549142517\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 3, Average Training Loss: 0.060603954099320075\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 3, Average Validation Loss: 0.27666279390968124\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 4, Average Training Loss: 0.03833474657613556\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 4, Average Validation Loss: 0.2808116000659507\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 5, Average Training Loss: 0.038210714878421675\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 5, Average Validation Loss: 0.274385420477082\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 6, Average Training Loss: 0.03801245371324896\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 6, Average Validation Loss: 0.25426665899054757\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 7, Average Training Loss: 0.022220144817369804\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 7, Average Validation Loss: 0.25461014077581207\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 8, Average Training Loss: 0.012697465086864522\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 8, Average Validation Loss: 0.25509158560428125\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 9, Average Training Loss: 0.0065099258394945006\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 9, Average Validation Loss: 0.2555074726456198\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 10, Average Training Loss: 0.004163868848753068\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 10, Average Validation Loss: 0.25640234152047797\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 11, Average Training Loss: 0.0030326540398896325\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 11, Average Validation Loss: 0.25640488994018784\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 12, Average Training Loss: 0.0026038779212374857\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 12, Average Validation Loss: 0.25643057344031744\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 13, Average Training Loss: 0.0022318905390746714\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 13, Average Validation Loss: 0.2564657388319229\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 14, Average Training Loss: 0.00262620134442163\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 14, Average Validation Loss: 0.25707783216032487\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 15, Average Training Loss: 0.0022249480066582517\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 15, Average Validation Loss: 0.2573437772305875\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 16, Average Training Loss: 0.002098759089871959\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 16, Average Validation Loss: 0.25744061056396056\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 17, Average Training Loss: 0.0020316387712160603\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 17, Average Validation Loss: 0.2574771998514389\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 18, Average Training Loss: 0.001996726553400602\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 18, Average Validation Loss: 0.25748779618277634\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 19, Average Training Loss: 0.00198952672855033\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 19, Average Validation Loss: 0.2575122908656967\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 20, Average Training Loss: 0.0019828716261430933\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 20, Average Validation Loss: 0.2575330721407101\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 21, Average Training Loss: 0.0019766887330538215\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 21, Average Validation Loss: 0.2575507453032609\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 22, Average Training Loss: 0.001970886853651063\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 22, Average Validation Loss: 0.2575657649672237\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 23, Average Training Loss: 0.001965392469030217\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 23, Average Validation Loss: 0.2575785730933321\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 24, Average Training Loss: 0.0019601453564937555\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 24, Average Validation Loss: 0.25758949127690545\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 25, Average Training Loss: 0.0019551009555311824\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 25, Average Validation Loss: 0.25759883989290944\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 26, Average Training Loss: 0.0019502230870383785\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 26, Average Validation Loss: 0.2576068499735717\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 27, Average Training Loss: 0.0019454852469683761\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 27, Average Validation Loss: 0.2576136968002237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 28, Average Training Loss: 0.0019408660065185657\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 28, Average Validation Loss: 0.257619595219349\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 29, Average Training Loss: 0.0019363470671212918\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 29, Average Validation Loss: 0.2576246576319481\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 30, Average Training Loss: 0.0019319142894070876\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 30, Average Validation Loss: 0.2576290212314704\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 31, Average Training Loss: 0.0019275559500177095\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 31, Average Validation Loss: 0.2576327799209233\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 32, Average Training Loss: 0.001923263125524162\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 32, Average Validation Loss: 0.25763601302329836\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 33, Average Training Loss: 0.0019190276431113186\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 33, Average Validation Loss: 0.25763880499991876\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 34, Average Training Loss: 0.0019148423299476555\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 34, Average Validation Loss: 0.2576412019673093\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 35, Average Training Loss: 0.0019107020113265784\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 35, Average Validation Loss: 0.25764326314473973\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 36, Average Training Loss: 0.0019066019553088704\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 36, Average Validation Loss: 0.25764503336415207\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 37, Average Training Loss: 0.0019025381175177848\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 37, Average Validation Loss: 0.2576465667064848\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 38, Average Training Loss: 0.0018985072062397176\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 38, Average Validation Loss: 0.25764785822609376\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 39, Average Training Loss: 0.0018945060548081778\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 39, Average Validation Loss: 0.25764897484974614\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 40, Average Training Loss: 0.0018905322914679798\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 40, Average Validation Loss: 0.2576499027681762\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 41, Average Training Loss: 0.0018865837321277565\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 41, Average Validation Loss: 0.25765071147731666\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 42, Average Training Loss: 0.001882657749763164\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 42, Average Validation Loss: 0.25765138569063156\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 43, Average Training Loss: 0.0018787535728535987\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 43, Average Validation Loss: 0.2576519266284745\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 44, Average Training Loss: 0.0018748695571154388\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 44, Average Validation Loss: 0.25765238644490984\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 45, Average Training Loss: 0.0018710030960998793\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 45, Average Validation Loss: 0.2576527378425516\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 46, Average Training Loss: 0.0018671540278107773\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 46, Average Validation Loss: 0.2576530149270748\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 47, Average Training Loss: 0.0018633222763421965\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 47, Average Validation Loss: 0.25765323369153614\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 48, Average Training Loss: 0.0018595054262004074\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 48, Average Validation Loss: 0.2576533631774886\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 49, Average Training Loss: 0.0018557037330271641\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 49, Average Validation Loss: 0.2576534337010877\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 50, Average Training Loss: 0.0018519159401000239\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 50, Average Validation Loss: 0.25765344930876943\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 51, Average Training Loss: 0.0018481416201143119\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 51, Average Validation Loss: 0.25765343858250256\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 52, Average Training Loss: 0.0018443800954434327\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 52, Average Validation Loss: 0.2576533658751126\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 53, Average Training Loss: 0.0018406310868686313\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 53, Average Validation Loss: 0.2576532905985569\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 54, Average Training Loss: 0.001836893167577725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 54, Average Validation Loss: 0.2576531374762798\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 55, Average Training Loss: 0.0018331668304107556\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 55, Average Validation Loss: 0.2576529874370016\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 56, Average Training Loss: 0.0018294513268238277\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 56, Average Validation Loss: 0.2576528054116101\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 57, Average Training Loss: 0.001825746433508177\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 57, Average Validation Loss: 0.25765258343569164\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 58, Average Training Loss: 0.0018220514217916555\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 58, Average Validation Loss: 0.2576523491277777\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 59, Average Training Loss: 0.0018183656152275525\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 59, Average Validation Loss: 0.25765209336732997\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 60, Average Training Loss: 0.0018146897020200293\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 60, Average Validation Loss: 0.25765182450413704\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 61, Average Training Loss: 0.0018110228336868598\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 61, Average Validation Loss: 0.2576515332892023\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 62, Average Training Loss: 0.0018073648415458856\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 62, Average Validation Loss: 0.25765124078968477\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 63, Average Training Loss: 0.0018037154613856617\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 63, Average Validation Loss: 0.25765091964396936\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 64, Average Training Loss: 0.001800075376711509\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 64, Average Validation Loss: 0.2576506150693729\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 65, Average Training Loss: 0.0017964431974739777\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 65, Average Validation Loss: 0.2576502788298089\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 66, Average Training Loss: 0.0017928184606406472\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 66, Average Validation Loss: 0.2576499284598334\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 67, Average Training Loss: 0.0017892025437790259\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 67, Average Validation Loss: 0.25764956350984247\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 68, Average Training Loss: 0.0017855941298269371\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 68, Average Validation Loss: 0.25764919701835204\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 69, Average Training Loss: 0.0017819933208547847\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 69, Average Validation Loss: 0.25764881562570047\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 70, Average Training Loss: 0.0017784002265504762\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 70, Average Validation Loss: 0.257648432049258\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 71, Average Training Loss: 0.0017748144020559597\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 71, Average Validation Loss: 0.25764802791948976\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 72, Average Training Loss: 0.0017712361145013438\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 72, Average Validation Loss: 0.2576476275150118\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 73, Average Training Loss: 0.0017676649945619176\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 73, Average Validation Loss: 0.25764722621132585\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 74, Average Training Loss: 0.001764100652109735\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 74, Average Validation Loss: 0.2576468213108079\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 75, Average Training Loss: 0.0017605433447737244\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 75, Average Validation Loss: 0.2576464043352111\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 76, Average Training Loss: 0.0017569927968540868\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 76, Average Validation Loss: 0.2576459767618056\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 77, Average Training Loss: 0.0017534488577602343\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 77, Average Validation Loss: 0.257645562162687\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 78, Average Training Loss: 0.0017499122956180137\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 78, Average Validation Loss: 0.25764511564168435\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 79, Average Training Loss: 0.0017463824379550636\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 79, Average Validation Loss: 0.2576446896097783\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 80, Average Training Loss: 0.0017428583535523078\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 80, Average Validation Loss: 0.25764424591485796\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 99.6%\n",
      "Epoch 81, Average Training Loss: 0.001739340832705012\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 81, Average Validation Loss: 0.257643796567773\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 82, Average Training Loss: 0.0017358301422948873\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 82, Average Validation Loss: 0.2576433476060629\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 83, Average Training Loss: 0.0017323257650769014\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 83, Average Validation Loss: 0.2576429109121191\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 84, Average Training Loss: 0.0017288271294899117\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 84, Average Validation Loss: 0.25764244595735236\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 85, Average Training Loss: 0.0017253351740393016\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 85, Average Validation Loss: 0.25764199667449655\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 86, Average Training Loss: 0.0017218489228152626\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 86, Average Validation Loss: 0.25764153088475095\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 87, Average Training Loss: 0.001718368949614509\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 87, Average Validation Loss: 0.25764107183906537\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 88, Average Training Loss: 0.0017148953805191398\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 88, Average Validation Loss: 0.25764060958192264\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 89, Average Training Loss: 0.001711427316373972\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 89, Average Validation Loss: 0.2576401486093628\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 90, Average Training Loss: 0.0017079658128035017\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 90, Average Validation Loss: 0.2576396655419777\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 91, Average Training Loss: 0.0017045102347811925\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 91, Average Validation Loss: 0.25763918921865264\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 92, Average Training Loss: 0.0017010610543438504\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 92, Average Validation Loss: 0.25763871501488933\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 93, Average Training Loss: 0.0016976162866971774\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 93, Average Validation Loss: 0.25763821466986475\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 94, Average Training Loss: 0.0016941777345605836\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 94, Average Validation Loss: 0.2576377409799346\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 95, Average Training Loss: 0.001690745418716605\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 95, Average Validation Loss: 0.2576372570775706\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 96, Average Training Loss: 0.001687318445164293\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 96, Average Validation Loss: 0.2576367502454026\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 97, Average Training Loss: 0.0016838970575188544\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 97, Average Validation Loss: 0.25763626409501866\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 98, Average Training Loss: 0.0016804817332404269\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 98, Average Validation Loss: 0.25763578327565356\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 99, Average Training Loss: 0.001677071898697894\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 99, Average Validation Loss: 0.2576352634049695\n",
      "train 0.0%\n",
      "train 7.1%\n",
      "train 14.2%\n",
      "train 21.3%\n",
      "train 28.4%\n",
      "train 35.6%\n",
      "train 42.7%\n",
      "train 49.8%\n",
      "train 56.9%\n",
      "train 64.0%\n",
      "train 71.1%\n",
      "train 78.2%\n",
      "train 85.3%\n",
      "train 92.5%\n",
      "train 99.6%\n",
      "Epoch 100, Average Training Loss: 0.001673667015553191\n",
      "val 0.0%\n",
      "val 86.2%\n",
      "Epoch 100, Average Validation Loss: 0.2576347818148547\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 999999\n",
    "train_l = []\n",
    "val_l = []\n",
    "with open(f'log_resnet50_{version}.txt','w') as f:\n",
    "    for epoch in range(100):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_image_ids = list(train_mem_scores.keys())\n",
    "        train_mem_scores_list = list(train_mem_scores.values())\n",
    "        num_train_batches = len(train_image_ids) // batch_size\n",
    "        avg_train_loss = 0\n",
    "        for i in range(num_train_batches):\n",
    "            if i % 100 == 0:\n",
    "                print(f'train {100*i/num_train_batches:.1f}%')\n",
    "                f.write(f'train {100*i/num_train_batches:.1f}%\\n')\n",
    "                f.flush()\n",
    "            batch_ids = train_image_ids[i*batch_size:(i+1)*batch_size]\n",
    "            batch_scores = torch.tensor(train_mem_scores_list[i*batch_size:(i+1)*batch_size], dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "            batch_images = torch.stack([load_and_preprocess_image(f\"./lamem/images/{image_id}\") for image_id in batch_ids]).to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(batch_images)\n",
    "            loss = huber_loss(outputs, normalize_scores(batch_scores))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_train_loss += loss.item()\n",
    "    #         break\n",
    "        avg_train_loss /= num_train_batches\n",
    "        train_l.append(avg_train_loss)\n",
    "        print(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}')\n",
    "        f.write(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\\n')\n",
    "        f.flush()\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        val_image_ids = list(val_mem_scores.keys())\n",
    "        val_mem_scores_list = list(val_mem_scores.values())\n",
    "        num_val_batches = len(val_image_ids) // batch_size\n",
    "        with torch.no_grad():\n",
    "            avg_val_loss = 0\n",
    "            for i in range(num_val_batches):\n",
    "                if i % 100 == 0:\n",
    "                    print(f'val {100*i/num_val_batches:.1f}%')\n",
    "                    f.write(f'val {100*i/num_val_batches:.1f}%\\n')\n",
    "                    f.flush()\n",
    "                batch_ids = val_image_ids[i*batch_size:(i+1)*batch_size]\n",
    "                batch_scores = torch.tensor(val_mem_scores_list[i*batch_size:(i+1)*batch_size], dtype=torch.float32).to(device)\n",
    "\n",
    "                batch_images = torch.stack([load_and_preprocess_image(f\"./lamem/images/{image_id}\") for image_id in batch_ids]).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(batch_images)\n",
    "                loss = huber_loss(outputs, normalize_scores(batch_scores))\n",
    "\n",
    "                avg_val_loss += loss.item()\n",
    "    #             break\n",
    "\n",
    "            avg_val_loss = avg_val_loss / num_val_batches\n",
    "            val_l.append(avg_val_loss)\n",
    "            print(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss}')\n",
    "            f.write(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss}\\n')\n",
    "            f.flush()\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('save best epoch',epoch,avg_val_loss)\n",
    "                f.write(f'save best epoch {epoch} {avg_val_loss}\\n')\n",
    "                f.flush()\n",
    "                torch.save(model.state_dict(), f'resnet50_{version}.pth')\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb8564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_env)",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
