{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f78d6cb",
   "metadata": {},
   "source": [
    "## Initialize AlexNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c87ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.models as models\n",
    "\n",
    "# Download and load the pre-trained AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Print the model architecture\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2332661",
   "metadata": {},
   "source": [
    "## Intialize forward hooks to get each layer activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55dcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "activation = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "#         print(f\"{module.__class__.__name__} output shape:\", output.shape)\n",
    "        activation[module] = output.detach()\n",
    "\n",
    "conv_layers = [layer for layer in alexnet.features if isinstance(layer, nn.Conv2d)]\n",
    "\n",
    "fc_layers = [layer for layer in alexnet.classifier if isinstance(layer, nn.Linear)]\n",
    "\n",
    "# Register hooks for each Conv and FC layer\n",
    "for layer in conv_layers + fc_layers:\n",
    "    layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0e158",
   "metadata": {},
   "source": [
    "## Test on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66d11ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label:  'gondola',\n",
      "Predicted probability: 0.20543523132801056\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"./lamem/images/00000002.jpg\")\n",
    "\n",
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move input batch to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_batch = input_batch.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "alexnet.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = alexnet(input_batch)\n",
    "\n",
    "# Convert output probabilities to predicted class\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "predicted_class = torch.argmax(probabilities)\n",
    "\n",
    "# Load the ImageNet class labels\n",
    "with open(\"./imagenet_class_labels.txt\") as f:  # Replace \"imagenet_classes.txt\" with the file containing class labels\n",
    "    class_labels = [line.strip()[4:] for line in f.readlines()]\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(\"Predicted class label:\", predicted_label)\n",
    "print(\"Predicted probability:\", probabilities[predicted_class].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d03effe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n",
       " Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
       " Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Linear(in_features=9216, out_features=4096, bias=True),\n",
       " Linear(in_features=4096, out_features=4096, bias=True),\n",
       " Linear(in_features=4096, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(activation.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a2c9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(132950.4062), tensor(100160.9141))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(activation[list(activation.keys())[0]]).sum(),(activation[list(activation.keys())[1]]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c7e434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(activation.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce639d",
   "metadata": {},
   "source": [
    "## Run experiment on memorability test set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40fe393",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mem_scores = {}\n",
    "with open('./lamem/splits/test_1.txt') as f:\n",
    "    for line in f:\n",
    "        image_id, mem_score = line.strip().split(' ')\n",
    "        image_mem_scores[image_id] = float(mem_score)\n",
    "\n",
    "# Load the ImageNet class labels\n",
    "with open(\"./imagenet_class_labels.txt\") as f:  # Replace \"imagenet_classes.txt\" with the file containing class labels\n",
    "    class_labels = [line.strip()[4:] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "1.0 %\n",
      "2.0 %\n",
      "3.0 %\n",
      "4.0 %\n",
      "5.0 %\n",
      "6.0 %\n",
      "7.0 %\n",
      "8.0 %\n",
      "9.0 %\n",
      "10.0 %\n",
      "11.0 %\n",
      "12.0 %\n",
      "13.0 %\n",
      "14.0 %\n",
      "15.0 %\n",
      "16.0 %\n",
      "17.0 %\n",
      "18.0 %\n",
      "19.0 %\n",
      "20.0 %\n",
      "21.0 %\n",
      "22.0 %\n",
      "23.0 %\n",
      "24.0 %\n",
      "25.0 %\n",
      "26.0 %\n",
      "27.0 %\n",
      "28.0 %\n",
      "29.0 %\n",
      "30.0 %\n",
      "31.0 %\n",
      "32.0 %\n",
      "33.0 %\n",
      "34.0 %\n",
      "35.0 %\n",
      "36.0 %\n",
      "37.0 %\n",
      "38.0 %\n"
     ]
    }
   ],
   "source": [
    "alexnet.eval()\n",
    "predictions = {}\n",
    "layer_ids = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "image_layer_responses = {}\n",
    "for i,image_id in enumerate(image_mem_scores):\n",
    "    if i % 100 == 0:\n",
    "        print(100*i/len(image_mem_scores),'%')\n",
    "    activation = {}\n",
    "    layer_response = {}\n",
    "    image = Image.open(f\"./lamem/images/{image_id}\")\n",
    "\n",
    "    # Preprocess\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),  # Ensure the image has three channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = alexnet(input_batch)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    predicted_class = torch.argmax(probabilities)\n",
    "\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "    predictions[image_id] = [predicted_label,probabilities[predicted_class].item()]\n",
    "    \n",
    "    for j,key in enumerate(activation.keys()):\n",
    "        layer_response[layer_ids[j]] = activation[key].sum().item()\n",
    "    image_layer_responses[image_id] = layer_response\n",
    "#     print(layer_response,image_mem_scores[image_id])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac0844",
   "metadata": {},
   "source": [
    "## Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_distributions = {}\n",
    "for layer_id in layer_ids:\n",
    "    layer_distributions[layer_id] = {'activations':[],'mem_scores':[]}\n",
    "    \n",
    "for image_id, layer_response_dict in image_layer_responses.items():\n",
    "    for layer_id, layer_response in layer_response_dict.items():\n",
    "        layer_distributions[layer_id]['activations'].append(layer_response)\n",
    "        layer_distributions[layer_id]['mem_scores'].append(image_mem_scores[image_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e980b7",
   "metadata": {},
   "source": [
    "## Calculate Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35619e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "coeffs = []\n",
    "for layer_id, activations_and_mem_scores in layer_distributions.items():\n",
    "    x,y = activations_and_mem_scores['activations'],activations_and_mem_scores['mem_scores']\n",
    "    corr_coefficient, p_value = pearsonr(x,y)\n",
    "    print(layer_id)\n",
    "    print(\"Pearson correlation coefficient:\", corr_coefficient)\n",
    "    print(\"p-value:\", p_value,'\\n')\n",
    "    coeffs.append(corr_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f996c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(layer_ids,coeffs,marker='o',color='k')\n",
    "plt.title('AlexNet layer activation correlation with image memorability')\n",
    "plt.xlabel('Model layer (1-5 conv, 6-8 fc)')\n",
    "plt.ylabel('Pearson correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299349ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
